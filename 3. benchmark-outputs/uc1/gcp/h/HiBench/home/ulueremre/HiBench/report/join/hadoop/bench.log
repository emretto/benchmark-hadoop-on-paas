SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/usr/lib/hadoop/lib/slf4j-log4j12-1.7.25.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/home/ulueremre/HiBench/hadoopbench/sql/target/apache-hive-0.14.0-bin/lib/hive-jdbc-0.14.0-standalone.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/usr/lib/hadoop/lib/slf4j-log4j12-1.7.25.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/home/ulueremre/HiBench/hadoopbench/sql/target/apache-hive-0.14.0-bin/lib/hive-jdbc-0.14.0-standalone.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]

Logging initialized using configuration in jar:file:/home/ulueremre/HiBench/hadoopbench/sql/target/apache-hive-0.14.0-bin/lib/hive-common-0.14.0.jar!/hive-log4j.properties
OK
Time taken: 0.547 seconds
OK
Time taken: 0.036 seconds
OK
Time taken: 0.298 seconds
OK
Time taken: 0.007 seconds
OK
Time taken: 0.032 seconds
OK
Time taken: 0.007 seconds
OK
Time taken: 0.078 seconds
Query ID = ulueremre_20201213170505_0839d6a4-0496-4d62-aa60-9a161601dc20
Total jobs = 3
Stage-1 is selected by condition resolver.
Launching Job 1 out of 3
Number of reduce tasks not specified. Defaulting to jobconf value of: 12
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1607867764932_0023, Tracking URL = http://hadoop-cluster-m:8088/proxy/application_1607867764932_0023/
Kill Command = /usr/lib/hadoop/bin/hadoop job  -kill job_1607867764932_0023
Hadoop job information for Stage-1: number of mappers: 36; number of reducers: 12
2020-12-13 17:06:07,314 Stage-1 map = 0%,  reduce = 0%
2020-12-13 17:06:26,869 Stage-1 map = 11%,  reduce = 0%, Cumulative CPU 71.28 sec
2020-12-13 17:06:28,993 Stage-1 map = 13%,  reduce = 0%, Cumulative CPU 116.95 sec
2020-12-13 17:06:30,031 Stage-1 map = 14%,  reduce = 0%, Cumulative CPU 127.45 sec
2020-12-13 17:06:33,109 Stage-1 map = 17%,  reduce = 0%, Cumulative CPU 146.62 sec
2020-12-13 17:06:34,135 Stage-1 map = 18%,  reduce = 0%, Cumulative CPU 147.63 sec
2020-12-13 17:06:35,160 Stage-1 map = 23%,  reduce = 0%, Cumulative CPU 176.75 sec
2020-12-13 17:06:38,244 Stage-1 map = 26%,  reduce = 0%, Cumulative CPU 184.36 sec
2020-12-13 17:06:39,272 Stage-1 map = 29%,  reduce = 0%, Cumulative CPU 192.72 sec
2020-12-13 17:06:42,352 Stage-1 map = 32%,  reduce = 0%, Cumulative CPU 206.4 sec
2020-12-13 17:06:43,375 Stage-1 map = 33%,  reduce = 0%, Cumulative CPU 207.89 sec
2020-12-13 17:06:44,396 Stage-1 map = 39%,  reduce = 0%, Cumulative CPU 227.47 sec
2020-12-13 17:06:50,558 Stage-1 map = 40%,  reduce = 0%, Cumulative CPU 240.88 sec
2020-12-13 17:06:52,622 Stage-1 map = 41%,  reduce = 0%, Cumulative CPU 254.34 sec
2020-12-13 17:06:54,675 Stage-1 map = 42%,  reduce = 0%, Cumulative CPU 269.99 sec
2020-12-13 17:06:55,698 Stage-1 map = 45%,  reduce = 0%, Cumulative CPU 277.13 sec
2020-12-13 17:06:56,719 Stage-1 map = 49%,  reduce = 0%, Cumulative CPU 297.88 sec
2020-12-13 17:06:57,745 Stage-1 map = 57%,  reduce = 0%, Cumulative CPU 327.29 sec
2020-12-13 17:06:58,768 Stage-1 map = 60%,  reduce = 0%, Cumulative CPU 334.96 sec
2020-12-13 17:06:59,798 Stage-1 map = 67%,  reduce = 0%, Cumulative CPU 355.45 sec
2020-12-13 17:07:02,862 Stage-1 map = 68%,  reduce = 0%, Cumulative CPU 360.62 sec
2020-12-13 17:07:08,992 Stage-1 map = 71%,  reduce = 0%, Cumulative CPU 372.16 sec
2020-12-13 17:07:10,012 Stage-1 map = 77%,  reduce = 0%, Cumulative CPU 385.91 sec
2020-12-13 17:07:12,056 Stage-1 map = 79%,  reduce = 0%, Cumulative CPU 393.27 sec
2020-12-13 17:07:14,099 Stage-1 map = 82%,  reduce = 0%, Cumulative CPU 401.02 sec
2020-12-13 17:07:15,118 Stage-1 map = 88%,  reduce = 0%, Cumulative CPU 418.89 sec
2020-12-13 17:07:16,138 Stage-1 map = 92%,  reduce = 0%, Cumulative CPU 426.72 sec
2020-12-13 17:07:17,158 Stage-1 map = 96%,  reduce = 0%, Cumulative CPU 452.38 sec
2020-12-13 17:07:18,178 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 466.73 sec
2020-12-13 17:07:29,405 Stage-1 map = 100%,  reduce = 8%, Cumulative CPU 473.96 sec
2020-12-13 17:07:30,427 Stage-1 map = 100%,  reduce = 25%, Cumulative CPU 487.73 sec
2020-12-13 17:07:32,475 Stage-1 map = 100%,  reduce = 33%, Cumulative CPU 495.32 sec
2020-12-13 17:07:33,495 Stage-1 map = 100%,  reduce = 58%, Cumulative CPU 516.09 sec
2020-12-13 17:07:35,535 Stage-1 map = 100%,  reduce = 75%, Cumulative CPU 531.03 sec
2020-12-13 17:07:36,557 Stage-1 map = 100%,  reduce = 92%, Cumulative CPU 545.48 sec
2020-12-13 17:07:37,576 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 551.9 sec
MapReduce Total cumulative CPU time: 9 minutes 11 seconds 900 msec
Ended Job = job_1607867764932_0023
Launching Job 2 out of 3
Number of reduce tasks not specified. Defaulting to jobconf value of: 12
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1607867764932_0024, Tracking URL = http://hadoop-cluster-m:8088/proxy/application_1607867764932_0024/
Kill Command = /usr/lib/hadoop/bin/hadoop job  -kill job_1607867764932_0024
Hadoop job information for Stage-2: number of mappers: 12; number of reducers: 12
2020-12-13 17:07:45,253 Stage-2 map = 0%,  reduce = 0%
2020-12-13 17:07:56,573 Stage-2 map = 25%,  reduce = 0%, Cumulative CPU 14.33 sec
2020-12-13 17:07:58,620 Stage-2 map = 42%,  reduce = 0%, Cumulative CPU 18.39 sec
2020-12-13 17:07:59,650 Stage-2 map = 75%,  reduce = 0%, Cumulative CPU 43.37 sec
2020-12-13 17:08:00,671 Stage-2 map = 92%,  reduce = 0%, Cumulative CPU 54.06 sec
2020-12-13 17:08:01,694 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 57.44 sec
2020-12-13 17:08:10,887 Stage-2 map = 100%,  reduce = 8%, Cumulative CPU 61.38 sec
2020-12-13 17:08:11,912 Stage-2 map = 100%,  reduce = 25%, Cumulative CPU 69.55 sec
2020-12-13 17:08:13,952 Stage-2 map = 100%,  reduce = 33%, Cumulative CPU 74.02 sec
2020-12-13 17:08:14,975 Stage-2 map = 100%,  reduce = 50%, Cumulative CPU 81.8 sec
2020-12-13 17:08:16,024 Stage-2 map = 100%,  reduce = 58%, Cumulative CPU 85.36 sec
2020-12-13 17:08:17,049 Stage-2 map = 100%,  reduce = 75%, Cumulative CPU 94.1 sec
2020-12-13 17:08:18,067 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 106.51 sec
MapReduce Total cumulative CPU time: 1 minutes 46 seconds 510 msec
Ended Job = job_1607867764932_0024
Launching Job 3 out of 3
Number of reduce tasks determined at compile time: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1607867764932_0025, Tracking URL = http://hadoop-cluster-m:8088/proxy/application_1607867764932_0025/
Kill Command = /usr/lib/hadoop/bin/hadoop job  -kill job_1607867764932_0025
Hadoop job information for Stage-3: number of mappers: 12; number of reducers: 1
2020-12-13 17:08:25,690 Stage-3 map = 0%,  reduce = 0%
2020-12-13 17:08:35,973 Stage-3 map = 17%,  reduce = 0%, Cumulative CPU 7.73 sec
2020-12-13 17:08:36,994 Stage-3 map = 25%,  reduce = 0%, Cumulative CPU 11.39 sec
2020-12-13 17:08:40,054 Stage-3 map = 75%,  reduce = 0%, Cumulative CPU 41.06 sec
2020-12-13 17:08:41,074 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 54.79 sec
2020-12-13 17:08:49,226 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 59.99 sec
MapReduce Total cumulative CPU time: 59 seconds 990 msec
Ended Job = job_1607867764932_0025
Loading data to table default.rankings_uservisits_join
MapReduce Jobs Launched:
Stage-Stage-1: Map: 36  Reduce: 12   Cumulative CPU: 551.9 sec   HDFS Read: 1919312704 HDFS Write: 12714470 SUCCESS
Stage-Stage-2: Map: 12  Reduce: 12   Cumulative CPU: 106.51 sec   HDFS Read: 12719378 HDFS Write: 11282822 SUCCESS
Stage-Stage-3: Map: 12  Reduce: 1   Cumulative CPU: 59.99 sec   HDFS Read: 11287730 HDFS Write: 10009231 SUCCESS
Total MapReduce CPU Time Spent: 11 minutes 58 seconds 400 msec
OK
Time taken: 171.46 seconds
